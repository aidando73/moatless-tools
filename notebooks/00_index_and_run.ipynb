{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fea6d23c616b470",
   "metadata": {},
   "source": [
    "# Run Moatless Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c80c1cba7d5c37",
   "metadata": {},
   "source": [
    "First, index the codebase in a vector store.\n",
    "\n",
    "Set `repo_dir` to the path of the repository you want to index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9dd5259592cc65e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T05:14:44.351498Z",
     "start_time": "2024-06-17T05:14:22.983524Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aidand/dev/moatless-tools/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Parsing nodes: 100%|██████████| 5806/5806 [02:26<00:00, 39.55it/s]\n",
      "Generating embeddings: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 0 nodes and 0 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from moatless.index import CodeIndex, IndexSettings\n",
    "from moatless.repository import FileRepository\n",
    "from moatless.workspace import Workspace\n",
    "\n",
    "# An OPENAI_API_KEY is required to use the OpenAI Models\n",
    "model = \"gpt-4o-2024-05-13\"\n",
    "index_settings = IndexSettings(\n",
    "    embed_model=\"text-embedding-3-small\"\n",
    ")\n",
    "\n",
    "repo_dir = \"/Users/aidand/dev/hello-swe-bench/django\"\n",
    "file_repo = FileRepository(repo_path=repo_dir)\n",
    "\n",
    "code_index = CodeIndex(file_repo=file_repo, settings=index_settings)\n",
    "nodes, tokens = code_index.run_ingestion()\n",
    "\n",
    "print(f\"Indexed {nodes} nodes and {tokens} tokens\")\n",
    "\n",
    "workspace = Workspace(file_repo=file_repo, code_index=code_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faa077aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:moatless.index.code_index:vector_search() Searching for query [....] and file pattern [None].\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:moatless.index.code_index:vector_search() Returning 0 search results. (Ignored 0 removed search results. Filtered out 0 search results.)\n",
      "INFO:moatless.index.code_index:semantic_search() Found 0 code spans in 0 files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SearchCodeResponse(message='Found 0 code spans.', hits=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_index.search(query=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13c37fd492267f",
   "metadata": {},
   "source": [
    "Then use the `SearchLoop` to find the relevant code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38c6f7f6422053fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T05:14:47.217658Z",
     "start_time": "2024-06-17T05:14:44.355086Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:moatless.transitions:{<class 'moatless.find.decide.DecideRelevance'>: {'max_iterations': 5}}\n",
      "INFO:Loop:Transitioning from Pending to SearchCode\n",
      "INFO:moatless.index.code_index:vector_search() Searching for query [\n",
      "Squashing migrations with Meta.index_together -> ...] and file pattern [None].\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:moatless.index.code_index:vector_search() Returning 0 search results. (Ignored 0 removed search results. Filtered out 0 search results.)\n",
      "INFO:moatless.index.code_index:semantic_search() Found 0 code spans in 0 files.\n",
      "INFO:moatless.trajectory:Getting transitions for SearchCode from 0 transitions.\n",
      "INFO:Loop:SearchCode Create completion with 2 messages\n",
      "\u001b[92m14:53:40 - LiteLLM:INFO\u001b[0m: utils.py:2794 - \n",
      "LiteLLM completion() model= gpt-4o-2024-05-13; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-2024-05-13; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m14:53:41 - LiteLLM:INFO\u001b[0m: utils.py:950 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "INFO:Loop:SearchCode: Received new action Search.\n",
      "INFO:moatless.index.code_index:vector_search() Searching for query [Meta.index_together file:**/migrations/**/*.py...] and file pattern [**/migrations/**/*.py].\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:moatless.index.code_index:vector_search() Returning 0 search results. (Ignored 0 removed search results. Filtered out 0 search results.)\n",
      "INFO:moatless.index.code_index:semantic_search() Found 0 code spans in 0 files.\n",
      "INFO:moatless.index.code_index:vector_search() Searching for query [Meta.indexes file:**/migrations/**/*.py...] and file pattern [**/migrations/**/*.py].\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:moatless.index.code_index:vector_search() Returning 0 search results. (Ignored 0 removed search results. Filtered out 0 search results.)\n",
      "INFO:moatless.index.code_index:semantic_search() Found 0 code spans in 0 files.\n",
      "INFO:moatless.index.code_index:vector_search() Searching for query [Meta.index_together file:**/models/**/*.py...] and file pattern [**/models/**/*.py].\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:moatless.index.code_index:vector_search() Returning 0 search results. (Ignored 0 removed search results. Filtered out 0 search results.)\n",
      "INFO:moatless.index.code_index:semantic_search() Found 0 code spans in 0 files.\n",
      "INFO:moatless.index.code_index:vector_search() Searching for query [Meta.indexes file:**/models/**/*.py...] and file pattern [**/models/**/*.py].\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:moatless.index.code_index:vector_search() Returning 0 search results. (Ignored 0 removed search results. Filtered out 0 search results.)\n",
      "INFO:moatless.index.code_index:semantic_search() Found 0 code spans in 0 files.\n",
      "INFO:moatless.find.search_v2:Found 0 hits.\n",
      "INFO:moatless.find.search_v2:No search results found. Will retry.\n",
      "INFO:moatless.trajectory:Saving action Search to SearchCode (1 actions)\n",
      "INFO:Loop:SearchCode: Retry requested. \n",
      "\n",
      "Unfortunately, I didn’t find any relevant results.\n",
      "INFO:moatless.index.code_index:vector_search() Searching for query [\n",
      "Squashing migrations with Meta.index_together -> ...] and file pattern [None].\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:moatless.index.code_index:vector_search() Returning 0 search results. (Ignored 0 removed search results. Filtered out 0 search results.)\n",
      "INFO:moatless.index.code_index:semantic_search() Found 0 code spans in 0 files.\n",
      "INFO:moatless.trajectory:Getting transitions for SearchCode from 0 transitions.\n",
      "INFO:Loop:SearchCode Create completion with 4 messages\n",
      "\u001b[92m14:53:50 - LiteLLM:INFO\u001b[0m: utils.py:2794 - \n",
      "LiteLLM completion() model= gpt-4o-2024-05-13; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-2024-05-13; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m14:53:51 - LiteLLM:INFO\u001b[0m: utils.py:950 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "INFO:Loop:SearchCode: Received new action Search.\n",
      "INFO:moatless.index.code_index:vector_search() Searching for query [Meta.index_together file:**/*.py...] and file pattern [**/*.py].\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:moatless.index.code_index:vector_search() Returning 0 search results. (Ignored 0 removed search results. Filtered out 0 search results.)\n",
      "INFO:moatless.index.code_index:semantic_search() Found 0 code spans in 0 files.\n",
      "INFO:moatless.index.code_index:vector_search() Searching for query [Meta.indexes file:**/*.py...] and file pattern [**/*.py].\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:moatless.index.code_index:vector_search() Returning 0 search results. (Ignored 0 removed search results. Filtered out 0 search results.)\n",
      "INFO:moatless.index.code_index:semantic_search() Found 0 code spans in 0 files.\n",
      "INFO:moatless.find.search_v2:Found 0 hits.\n",
      "INFO:moatless.find.search_v2:No search results found. Will retry.\n",
      "INFO:moatless.trajectory:Saving action Search to SearchCode (2 actions)\n",
      "INFO:Loop:SearchCode: Retry requested. \n",
      "\n",
      "Unfortunately, I didn’t find any relevant results.\n",
      "INFO:moatless.index.code_index:vector_search() Searching for query [\n",
      "Squashing migrations with Meta.index_together -> ...] and file pattern [None].\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:moatless.index.code_index:vector_search() Returning 0 search results. (Ignored 0 removed search results. Filtered out 0 search results.)\n",
      "INFO:moatless.index.code_index:semantic_search() Found 0 code spans in 0 files.\n",
      "INFO:moatless.trajectory:Getting transitions for SearchCode from 0 transitions.\n",
      "INFO:Loop:SearchCode Create completion with 6 messages\n",
      "\u001b[92m14:53:57 - LiteLLM:INFO\u001b[0m: utils.py:2794 - \n",
      "LiteLLM completion() model= gpt-4o-2024-05-13; provider = openai\n",
      "INFO:LiteLLM:\n",
      "LiteLLM completion() model= gpt-4o-2024-05-13; provider = openai\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m14:53:59 - LiteLLM:INFO\u001b[0m: utils.py:950 - Wrapper: Completed Call, calling success_handler\n",
      "INFO:LiteLLM:Wrapper: Completed Call, calling success_handler\n",
      "INFO:Loop:SearchCode: Received new action Search.\n",
      "INFO:moatless.index.code_index:vector_search() Searching for query [Django migration file:**/migrations/**/*.py...] and file pattern [**/migrations/**/*.py].\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:moatless.index.code_index:vector_search() Returning 0 search results. (Ignored 0 removed search results. Filtered out 0 search results.)\n",
      "INFO:moatless.index.code_index:semantic_search() Found 0 code spans in 0 files.\n",
      "INFO:moatless.find.search_v2:Found 0 hits.\n",
      "INFO:moatless.find.search_v2:No search results found. Will retry.\n",
      "INFO:moatless.trajectory:Saving action Search to SearchCode (3 actions)\n",
      "INFO:Loop:SearchCode: Retry requested. \n",
      "\n",
      "Unfortunately, I didn’t find any relevant results.\n",
      "WARNING:Loop:Max retries reached (2). Exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loop was aborted because the number of retries exceeded the limit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from moatless.transitions import search_transitions\n",
    "from moatless import AgenticLoop\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "instructions = \"\"\"\n",
    "Squashing migrations with Meta.index_together -> indexes transition should remove deprecation warnings.\n",
    "Description\n",
    "\n",
    "Squashing migrations with Meta.index_together -> Meta.indexes transition should remove deprecation warnings. As far as I'm aware, it's a 4.2 release blocker because you cannot get rid of the index_together deprecation warnings without rewriting migrations, see comment.\n",
    "\"\"\"\n",
    "\n",
    "transitions = search_transitions(model=model)\n",
    "search_loop = AgenticLoop(transitions, workspace=workspace)\n",
    "\n",
    "search_response = search_loop.run(instructions)\n",
    "print(search_response.message)\n",
    "\n",
    "print(workspace.file_context.create_prompt())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c160cc8c9c7e202e",
   "metadata": {},
   "source": [
    "Execute the `CodeLoop` to apply the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "903b67c9dff5c384",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T05:15:06.329522Z",
     "start_time": "2024-06-17T05:14:47.219845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The token limit check has been successfully removed from the `completion` function in moatless/llm/completion.py.\n"
     ]
    }
   ],
   "source": [
    "from moatless.transitions import code_transitions\n",
    "\n",
    "code_loop = AgenticLoop(transitions=code_transitions(), workspace=workspace)\n",
    "code_response = code_loop.run(instructions)\n",
    "\n",
    "print(f\"Response: {code_response.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d131ca3793b26a",
   "metadata": {},
   "source": [
    "Run a `$ git diff` to see the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51ba9eceb0b7288",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T05:15:06.434193Z",
     "start_time": "2024-06-17T05:15:06.332771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff --git a/moatless/llm/completion.py b/moatless/llm/completion.py\n",
      "index 2c95e47..a926948 100644\n",
      "--- a/moatless/llm/completion.py\n",
      "+++ b/moatless/llm/completion.py\n",
      "@@ -48,10 +48,6 @@ def completion(\n",
      " \n",
      "     metadata[\"trace_name\"] = trace_name\n",
      " \n",
      "-    tokens = token_counter(messages=messages[-1:])\n",
      "-    if tokens > Settings.max_message_tokens:\n",
      "-        raise ValueError(f\"Too many tokens in the new message: {tokens}\")\n",
      "-\n",
      "     response = litellm.completion(\n",
      "         model=model,\n",
      "         max_tokens=max_tokens,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "output = subprocess.run(\n",
    "      [\"git\", \"diff\"],\n",
    "      capture_output=True,\n",
    "      text=True,\n",
    "      cwd=repo_dir,\n",
    ")\n",
    "\n",
    "print(output.stdout)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
